from __future__ import annotations

import json
import logging
import sqlite3
import threading
import time


class SyncEngine:
    """Synchronize two SQLite databases via change streams.

    The engine installs triggers on a specified table in both databases.
    Triggers populate a ``change_log`` table that the background worker
    consumes to apply changes to the opposite database. Only basic
    ``INSERT`` and ``UPDATE`` operations are supported which is sufficient
    for tests and small examples.
    """

    def __init__(
        self,
        source: sqlite3.Connection,
        target: sqlite3.Connection,
        table: str,
        *,
        poll_interval: float = 0.05,
    ) -> None:
        self.source = source
        self.target = target
        self.table = table
        self.poll_interval = poll_interval
        self._stop = threading.Event()
        self._log = logging.getLogger("sync")

        self.columns = [
            r[1] for r in self.source.execute(f"PRAGMA table_info({table})").fetchall()
        ]
        self.pk = self.columns[0]

        for conn in (self.source, self.target):
            self._setup_change_log(conn)
            self._setup_triggers(conn)

        self._worker = threading.Thread(target=self._run, daemon=True)
        self._worker.start()

    # ------------------------------------------------------------------
    # Trigger / change-log setup
    # ------------------------------------------------------------------
    def _setup_change_log(self, conn: sqlite3.Connection) -> None:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS change_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                table_name TEXT,
                operation TEXT,
                row_id INTEGER,
                data TEXT,
                processed INTEGER DEFAULT 0
            )
            """
        )
        conn.commit()

    def _setup_triggers(self, conn: sqlite3.Connection) -> None:
        conn.execute(
            f"""
            CREATE TRIGGER IF NOT EXISTS {self.table}_after_insert
            AFTER INSERT ON {self.table}
            BEGIN
                INSERT INTO change_log(table_name, operation, row_id, data)
                VALUES (
                    '{self.table}',
                    'insert',
                    NEW.{self.pk},
                    json_object({self._json_columns('NEW')})
                );
            END;
            """
        )
        conn.execute(
            f"""
            CREATE TRIGGER IF NOT EXISTS {self.table}_after_update
            AFTER UPDATE ON {self.table}
            BEGIN
                INSERT INTO change_log(table_name, operation, row_id, data)
                VALUES (
                    '{self.table}',
                    'update',
                    NEW.{self.pk},
                    json_object({self._json_columns('NEW')})
                );
            END;
            """
        )
        conn.commit()

    # ------------------------------------------------------------------
    # Worker logic
    # ------------------------------------------------------------------
    def _run(self) -> None:
        while not self._stop.is_set():
            self._process(self.source, self.target)
            self._process(self.target, self.source)
            time.sleep(self.poll_interval)

    def _process(
        self,
        src: sqlite3.Connection,
        dest: sqlite3.Connection,
    ) -> None:
        self._log.info("start")
        try:
            rows = src.execute(
                "SELECT id, table_name, operation, data FROM change_log "
                "WHERE processed=0 ORDER BY id"
            ).fetchall()

            for change_id, table_name, operation, data in rows:
                self._apply_change(dest, table_name, operation, data)
                src.execute(
                    "UPDATE change_log SET processed=1 WHERE id=?",
                    (change_id,),
                )
            src.commit()
            dest.commit()
        except Exception:
            self._log.exception("error")
            raise
        else:
            self._log.info("end")

    def _apply_change(
        self,
        dest: sqlite3.Connection,
        table: str,
        operation: str,
        data: str,
    ) -> None:
        if operation not in {"insert", "update"}:
            return

        row = json.loads(data)
        placeholders = ",".join("?" for _ in self.columns)
        column_list = ",".join(self.columns)
        update_set = ",".join(
            f"{col}=excluded.{col}" for col in self.columns if col != self.pk
        )
        values = [row[col] for col in self.columns]
        dest.execute(
            f"INSERT INTO {table} ({column_list}) VALUES ({placeholders}) "
            f"ON CONFLICT({self.pk}) DO UPDATE SET {update_set}",
            values,
        )
        # Mark any change-log entries generated by this replication as processed
        dest.execute(
            "UPDATE change_log SET processed=1 WHERE table_name=? AND operation=? AND data=? AND processed=0",
            (table, operation, data),
        )

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def stop(self) -> None:
        """Stop the background worker and wait for it to finish."""
        self._stop.set()
        self._worker.join(timeout=1)

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _json_columns(self, prefix: str) -> str:
        return ", ".join(
            f"'{col}', {prefix}.{col}" for col in self.columns
        )
