#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Codex Repo Maintenance Orchestrator
- DB corruption auto-recovery hardening
- Repo-wide reference replacement (integrity_checker -> consolidation_validator)
- README/doc updates
- In-repo backup/temp cleanup (with safety)
- Gap logging + ChatGPT-5 research questions
- Test scaffolding for DB auto-recovery and environment compliance

USAGE:
  python tools/codex_repo_maint.py --repo . --db-path ./data/app.db --docs ./docs

Constraints:
- DO NOT ACTIVATE ANY GitHub Actions files.
"""

from __future__ import annotations

import argparse
import os
import re
import shutil
import sqlite3
import sys
from datetime import datetime
from pathlib import Path
from typing import Iterable, List, Optional, Tuple

OLD_SCRIPT = "scripts/database/database_integrity_checker.py"
NEW_SCRIPT = "scripts/database/database_consolidation_validator.py"

TEXT_EXTS = {
    ".py",
    ".md",
    ".rst",
    ".txt",
    ".sh",
    ".bat",
    ".ps1",
    ".yml",
    ".yaml",
    ".toml",
    ".ini",
    ".cfg",
    ".json",
    ".pyi",
    ".jinja",
    ".conf",
    ".env",
    ".properties",
}

GAPLOG = "CHANGELOG_CODEX_AUTO.md"
ERRLOG = "ERRORS_FOR_CHATGPT5.md"

BANNER = "# Auto-generated by codex_repo_maint.py\n"


def nowstamp() -> str:
    return datetime.now().strftime("%Y%m%d-%H%M%S")


def relsafe(path: Path, root: Path) -> bool:
    try:
        return path.resolve().is_relative_to(root.resolve())
    except AttributeError:
        try:
            path.resolve().relative_to(root.resolve())
            return True
        except Exception:
            return False


def append_file(path: Path, text: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("a", encoding="utf-8") as f:
        f.write(text.rstrip() + "\n")


def record_change(repo: Path, msg: str) -> None:
    append_file(repo / GAPLOG, f"- {datetime.now().isoformat()} — {msg}")


def record_error(repo: Path, step_num: str, step_desc: str, err: Exception, context: str) -> None:
    block = f"""
Question for ChatGPT-5:
While performing [{step_num}: {step_desc}], encountered the following error:
{repr(err)}
Context: {context}
What are the possible causes, and how can this be resolved while preserving intended functionality?
"""
    append_file(repo / ERRLOG, block)


def load_text(path: Path) -> Optional[str]:
    try:
        return path.read_text(encoding="utf-8")
    except Exception:
        return None


def save_text(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def grep_files(root: Path, needle: str, exts: Iterable[str]) -> List[Path]:
    hits = []
    for p in root.rglob("*"):
        if p.is_file() and p.suffix.lower() in exts:
            try:
                txt = p.read_text(encoding="utf-8", errors="ignore")
                if needle in txt:
                    hits.append(p)
            except Exception:
                pass
    return hits


def replace_in_file(path: Path, old: str, new: str) -> bool:
    txt = load_text(path)
    if txt is None or old not in txt:
        return False
    save_text(path, txt.replace(old, new))
    return True


def update_readme_env_and_refs(repo: Path) -> None:
    readme = repo / "README.md"
    if not readme.exists():
        return
    txt = load_text(readme) or ""
    changed = False

    if OLD_SCRIPT in txt:
        txt = txt.replace(OLD_SCRIPT, NEW_SCRIPT)
        changed = True
        record_change(repo, f"README: replaced `{OLD_SCRIPT}` → `{NEW_SCRIPT}`")

    env_header = "## Environment Requirements"
    block = (
        f"{env_header}\n\n"
        f"- Set `GH_COPILOT_BACKUP_ROOT` to an **absolute path outside this repository**.\n"
        f"- Ensure the directory exists or is creatable by the current user.\n"
        f"- This path is used for backups and recovery artifacts.\n"
    )
    if env_header not in txt:
        txt += "\n\n" + block
        changed = True
        record_change(repo, "README: appended Environment Requirements")

    if changed:
        save_text(readme, txt)


def validate_backup_env(repo: Path) -> Tuple[bool, str]:
    val = os.environ.get("GH_COPILOT_BACKUP_ROOT", "").strip()
    if not val:
        return False, "GH_COPILOT_BACKUP_ROOT is not set."
    path = Path(val)
    try:
        path.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        return False, f"Cannot create backup root at {val}: {e}"
    if relsafe(path, repo):
        return False, f"Backup root must be OUTSIDE the repository: {val}"
    return True, val


def cleanup_inrepo_temp(repo: Path) -> List[Path]:
    removed = []
    pattern = re.compile(r"(?i)(^|[._-])(backup|backups|temp|tmp)($|[._-])")
    for p in repo.rglob("*"):
        if p.is_dir() and pattern.search(p.name) and relsafe(p, repo):
            try:
                shutil.rmtree(p)
                removed.append(p)
            except Exception as e:
                record_error(repo, "Phase4-Step13", "Prune in-repo backup/temp", e, f"path={p}")
    if removed:
        record_change(
            repo,
            f"Removed in-repo backup/temp directories: {', '.join(str(r.relative_to(repo)) for r in removed)}",
        )
    return removed


def find_python_functions(root: Path, func_name: str) -> List[Path]:
    pattern = re.compile(rf"^\s*def\s+{re.escape(func_name)}\s*\(", re.M)
    hits = []
    for p in root.rglob("*.py"):
        txt = load_text(p)
        if not txt:
            continue
        if pattern.search(txt):
            hits.append(p)
    return hits


def patch_ensure_db(file_path: Path) -> bool:
    txt = load_text(file_path) or ""
    MARK = "# [codex-auto] corruption-guard"
    if MARK in txt:
        return False

    guard = f"""
{MARK}
def _codex_probe_sqlite_integrity(conn):
    try:
        try:
            cur = conn.execute("PRAGMA integrity_check")
            row = cur.fetchone()
            if row and isinstance(row[0], str) and row[0].lower() == "ok":
                return True
        except sqlite3.DatabaseError:
            pass
        conn.execute("PRAGMA schema_version")
        return True
    except sqlite3.DatabaseError:
        return False
"""

    if "import sqlite3" not in txt:
        txt = "import sqlite3\n" + txt
    txt += guard
    save_text(file_path, txt)
    record_change(file_path.parent, f"Injected integrity probe helper into {file_path}")
    return True


def write_recovery_support(repo: Path) -> Path:
    path = repo / "scripts" / "database" / "recovery_support.py"
    if path.exists():
        return path
    code = f'''# {BANNER.strip()}
import sqlite3, os
from pathlib import Path
from datetime import datetime


def ensure_db_with_recovery(db_path: str, create_tables_callable):
    dbp = Path(db_path)
    dbp.parent.mkdir(parents=True, exist_ok=True)

    def _rename_to_corrupt(p: Path) -> Path:
        new_suffix = p.suffix + ".corrupt." + datetime.now().strftime("%Y%m%d-%H%M%S")
        cp = p.with_suffix(new_suffix)
        if p.exists():
            p.rename(cp)
        return cp

    def _probe(conn: sqlite3.Connection) -> bool:
        try:
            try:
                cur = conn.execute("PRAGMA integrity_check")
                row = cur.fetchone()
                if row and isinstance(row[0], str) and row[0].lower() == "ok":
                    return True
            except sqlite3.DatabaseError:
                pass
            conn.execute("PRAGMA schema_version")
            return True
        except sqlite3.DatabaseError:
            return False

    try:
        conn = sqlite3.connect(str(dbp))
        ok = _probe(conn)
        conn.close()
        if not ok:
            _rename_to_corrupt(dbp)
            create_tables_callable(str(dbp))
            return "recreated"
        return "ok"
    except sqlite3.DatabaseError:
        _rename_to_corrupt(dbp)
        create_tables_callable(str(dbp))
        return "recreated"
'''
    save_text(path, code)
    record_change(repo, f"Created helper {path}")
    return path


def search_and_replace(repo: Path, old: str, new: str) -> List[Tuple[Path, int]]:
    changed = []
    for p in repo.rglob("*"):
        if p.is_file() and p.suffix.lower() in TEXT_EXTS:
            try:
                txt = p.read_text(encoding="utf-8", errors="ignore")
                if old in txt:
                    save_text(p, txt.replace(old, new))
                    changed.append((p, txt.count(old)))
            except Exception as e:
                record_error(repo, "Phase2-Step4", "search_and_replace", e, f"file={p}")
    if changed:
        record_change(repo, f"Renamed {len(changed)} files from {old} -> {new}")
    return changed


def check_doc_paths(repo: Path, docs_root: Optional[Path]) -> List[str]:
    missing = []
    patterns = [
        r"`([^`]*scripts/[^`]+)`",
        r"\b(scripts/[A-Za-z0-9_\-./]+)",
    ]
    if docs_root and not relsafe(docs_root, repo):
        docs_root = None
    scan_dirs = [docs_root] if docs_root else [repo]

    for dir_ in scan_dirs:
        for p in dir_.rglob("*"):
            if p.is_file() and p.suffix.lower() in {".md", ".rst", ".txt"}:
                txt = load_text(p) or ""
                for pat in patterns:
                    for m in re.finditer(pat, txt):
                        candidate = m.group(1)
                        if candidate.startswith("scripts/"):
                            full = repo / candidate
                            if not full.exists():
                                missing.append(candidate)
    if missing:
        record_change(repo, f"Docs missing paths: {len(missing)}")
    return sorted(set(missing))


def write_tests(repo: Path) -> None:
    tests_dir = repo / "tests"
    tests_dir.mkdir(exist_ok=True)

    test_db = tests_dir / "test_db_auto_recovery.py"
    if not test_db.exists():
        content = f'''# {BANNER.strip()}
import os
import sqlite3
from pathlib import Path

import pytest


def _minimal_create_tables(db_path: str):
    conn = sqlite3.connect(db_path)
    conn.execute("CREATE TABLE IF NOT EXISTS t(x INTEGER)")
    conn.commit()
    conn.close()


def corrupt_file(p: Path):
    p.write_bytes(b"not-a-sqlite-db")


def _ensure_func():
    try:
        from scripts.database.recovery_support import ensure_db_with_recovery
        return ensure_db_with_recovery
    except Exception:
        pytest.skip("recovery_support.ensure_db_with_recovery not available")


def test_auto_recovery_from_corrupt(tmp_path: Path):
    dbp = tmp_path / "app.db"
    corrupt_file(dbp)
    ensure = _ensure_func()
    status = ensure(str(dbp), _minimal_create_tables)
    assert status == "recreated", "DB should be recreated after corruption"


def test_integrity_ok(tmp_path: Path):
    dbp = tmp_path / "ok.db"
    _minimal_create_tables(str(dbp))
    ensure = _ensure_func()
    status = ensure(str(dbp), _minimal_create_tables)
    assert status in ("ok", "recreated")
'''
        save_text(test_db, content)
        record_change(repo, f"Added {test_db} for auto-recovery")

    test_env = tests_dir / "test_environment_compliance.py"
    if not test_env.exists():
        content = f'''# {BANNER.strip()}
import os
from pathlib import Path


def test_backup_root_outside_repo(tmp_path):
    repo = Path.cwd()
    val = os.environ.get("GH_COPILOT_BACKUP_ROOT")
    assert val, "GH_COPILOT_BACKUP_ROOT must be set"
    p = Path(val)
    assert repo not in p.resolve().parents and p.resolve() != repo.resolve()
'''
        save_text(test_env, content)
        record_change(repo, f"Added {test_env} for environment compliance")


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--repo", type=str, default=".")
    ap.add_argument("--db-path", type=str, required=False, help="Path to primary DB to probe (optional).")
    ap.add_argument("--docs", type=str, default=None, help="Docs root (optional).")
    args = ap.parse_args()

    repo = Path(args.repo).resolve()
    if not repo.exists():
        print(f"Repo path not found: {repo}", file=sys.stderr)
        sys.exit(2)

    try:
        (repo / GAPLOG).write_text(f"{BANNER}\n", encoding="utf-8")
        (repo / ERRLOG).write_text(f"{BANNER}\n", encoding="utf-8")
    except Exception as e:
        print(f"Cannot initialize logs: {e}", file=sys.stderr)
        sys.exit(2)

    try:
        search_and_replace(repo, OLD_SCRIPT, NEW_SCRIPT)
    except Exception as e:
        record_error(repo, "Phase2-Step4", "Replace obsolete script references", e, f"repo={repo}")

    try:
        update_readme_env_and_refs(repo)
    except Exception as e:
        record_error(repo, "Phase3-Step10", "README parsing & updates", e, f"repo={repo}")

    try:
        ok, detail = validate_backup_env(repo)
        if not ok:
            record_change(repo, f"ENV WARNING: {detail}")
        else:
            record_change(repo, f"ENV OK: GH_COPILOT_BACKUP_ROOT={detail}")
    except Exception as e:
        record_error(repo, "Phase3-Step6", "Validate backup env", e, "os.environ lookup")

    try:
        ensure_hits = find_python_functions(repo, "_ensure_db")
        if ensure_hits:
            for fp in ensure_hits:
                patch_ensure_db(fp)
        else:
            write_recovery_support(repo)
            record_change(repo, "No _ensure_db found; created recovery_support helper.")
    except Exception as e:
        record_error(repo, "Phase3-Step7", "Harden _ensure_db", e, "scan/patch")

    if args.db_path:
        try:
            from scripts.database.recovery_support import ensure_db_with_recovery as ensure_helper  # type: ignore
        except Exception:
            ensure_helper = None
        if ensure_helper:
            def _fallback_create_tables(db_path: str):
                conn = sqlite3.connect(db_path)
                conn.execute("CREATE TABLE IF NOT EXISTS codex_probe(id INTEGER PRIMARY KEY)")
                conn.commit()
                conn.close()
            try:
                status = ensure_helper(args.db_path, _fallback_create_tables)
                record_change(repo, f"DB probe: {args.db_path} → {status}")
            except Exception as e:
                record_error(repo, "Phase3-Step7", "DB probe via recovery helper", e, f"db_path={args.db_path}")

    try:
        docs_root = Path(args.docs).resolve() if args.docs else None
        missing = check_doc_paths(repo, docs_root)
        if missing:
            record_change(repo, f"Docs references missing: {len(missing)}; see {GAPLOG}")
            append_file(repo / GAPLOG, "Missing doc paths:\n" + "\n".join(f"  - {m}" for m in missing))
    except Exception as e:
        record_error(repo, "Phase3-Step11", "Docs path validation", e, f"docs={args.docs}")

    try:
        ok, _ = validate_backup_env(repo)
        if ok:
            cleanup_inrepo_temp(repo)
        else:
            record_change(repo, "Skipped pruning in-repo backups/temp: invalid env")
    except Exception as e:
        record_error(repo, "Phase4-Step13", "Prune backup/temp dirs", e, "")

    try:
        write_tests(repo)
    except Exception as e:
        record_error(repo, "Phase5-Step15", "Write tests", e, "")

    print("Codex repo maintenance — completed. See:")
    print(f" - {repo / GAPLOG}")
    print(f" - {repo / ERRLOG}")
    print("Reminder: DO NOT ACTIVATE ANY GitHub Actions files.")


if __name__ == "__main__":
    main()

