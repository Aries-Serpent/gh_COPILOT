#!/usr/bin/env python3
"""Autonomous File Management Module
===================================

Implements database-driven file organization, classification, backup, and
workspace optimization. All operations use the ``production.db`` database
located in the workspace root.

This module follows the guidelines from ``AUTONOMOUS_FILE_MANAGEMENT.instructions.md``
providing anti-recursion backup protection and enterprise compliance.
"""

from __future__ import annotations

import logging
import os
import shutil
import sqlite3
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Iterable, List, Sequence, Tuple


# Note: Logging configuration should be handled by the application using this module.
logger = logging.getLogger(__name__)


class BaseDatabaseManager:
    """Utility mixin providing a connection to ``production.db``."""

    def __init__(self, workspace_path: str = None) -> None:
        if workspace_path is None:
            workspace_path = os.getenv("WORKSPACE_PATH", "./workspace")
        self.workspace_path = Path(workspace_path)
        self.production_db = self.workspace_path / "production.db"

    def get_database_connection(self) -> sqlite3.Connection:
        """Return a connection to ``production.db``."""
        return sqlite3.connect(self.production_db)


class AutonomousFileManager(BaseDatabaseManager):
    """ðŸŽ¯ Autonomous File System Manager with Database Intelligence."""

    def organize_files_autonomously(self, file_patterns: Iterable[str]) -> Dict[str, str]:
        """Organize files using patterns from ``production.db``."""
        with self.get_database_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                """
                SELECT script_path, functionality_category, script_type
                FROM enhanced_script_tracking
                WHERE functionality_category IS NOT NULL
                """
            )
            organization_patterns = cursor.fetchall()

        organized: Dict[str, str] = {}
        for file_path in file_patterns:
            organized[file_path] = self.predict_optimal_location(file_path, organization_patterns)
        return organized

    def predict_optimal_location(self, file_path: str, patterns: Sequence[Tuple[str, str, str]]) -> str:
        """Predict an optimal destination for ``file_path`` based on patterns."""
        suffix = Path(file_path).suffix
        for script_path, category, _stype in patterns:
            if script_path.endswith(suffix):
                dest_dir = self.workspace_path / category
                return str(dest_dir / Path(file_path).name)
        return str(self.workspace_path / Path(file_path).name)


class IntelligentFileClassifier(BaseDatabaseManager):
    """ðŸ§  AI-Powered File Classification Engine."""

    def classify_file_autonomously(self, file_path: str) -> Dict[str, Any]:
        """Classify ``file_path`` using patterns from ``production.db``."""
        with self.get_database_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                """
                SELECT functionality_category, script_type, COUNT(*) as frequency
                FROM enhanced_script_tracking
                WHERE script_path LIKE ?
                GROUP BY functionality_category, script_type
                ORDER BY frequency DESC
                """,
                (f"%{Path(file_path).suffix}%",),
            )
            patterns = cursor.fetchall()

        category = patterns[0][0] if patterns else "general"
        stype = patterns[0][1] if patterns else "utility"
        confidence = self.calculate_classification_confidence(patterns)
        return {"category": category, "type": stype, "confidence": confidence}

    @staticmethod
    def calculate_classification_confidence(patterns: Sequence[Tuple]) -> float:
        """Return a confidence score based on pattern frequency."""
        if not patterns:
            return 0.0
        total = sum(p[2] for p in patterns)
        top = patterns[0][2]
        return round(top / total, 2)


class AutonomousBackupManager(BaseDatabaseManager):
    """ðŸ’¾ Autonomous Backup System with Anti-Recursion Protection."""

    FORBIDDEN_BACKUP_LOCATIONS = [
        "e:/gh_COPILOT",
        "C:/temp/",
        "./backup/",
    ]
    APPROVED_BACKUP_ROOT = Path("E:/temp/gh_COPILOT_Backups")

    def __init__(self, workspace_path: str = "e:/gh_COPILOT") -> None:
        super().__init__(workspace_path)
        self.backup_root = self.APPROVED_BACKUP_ROOT

    def validate_backup_location(self) -> bool:
        path_lower = str(self.backup_root).lower()
        if any(path_lower.startswith(p.lower()) for p in self.FORBIDDEN_BACKUP_LOCATIONS):
            return False
        # Prevent backups inside workspace
        return not str(self.workspace_path).lower().startswith(path_lower)

    def get_priority_threshold(self, priority: str) -> int:
        mapping = {"HIGH": 75, "MEDIUM": 50, "LOW": 0}
        return mapping.get(priority.upper(), 0)

    def execute_autonomous_backup(self, candidates: Sequence[Tuple[str, int, Any]]) -> str:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.backup_root / timestamp
        backup_dir.mkdir(parents=True, exist_ok=True)
        for file_path, _score, _last in candidates:
            src = Path(file_path)
            if not src.is_file():
                continue
            # Skip files already inside backup directory
            if backup_dir in src.parents:
                continue
            dest = backup_dir / src.name
            try:
                dest.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src, dest)
            except Exception as exc:
                logger.warning(f"Failed to backup {src}: {exc}")
        return str(backup_dir)

    def create_intelligent_backup(self, file_priority: str = "HIGH") -> str:
        if not self.validate_backup_location():
            raise RuntimeError("CRITICAL: Recursive backup violation prevented")

        threshold = self.get_priority_threshold(file_priority)
        with self.get_database_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                """
                SELECT script_path, importance_score, last_backup
                FROM enhanced_script_tracking
                WHERE importance_score >= ?
                ORDER BY importance_score DESC, last_backup ASC
                """,
                (threshold,),
            )
            candidates = cursor.fetchall()
        return self.execute_autonomous_backup(candidates)


class WorkspaceOptimizer(BaseDatabaseManager):
    """âš¡ Autonomous Workspace Optimization Engine."""

    def optimize_workspace_autonomously(self) -> Dict[str, Any]:
        results: Dict[str, Any] = {
            "files_organized": 0,
            "storage_optimized": "0 MB",
            "performance_improved": "0%",
            "enterprise_compliance": "PENDING",
        }

        with self.get_database_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                """
                SELECT COUNT(*) as total_files,
                       SUM(file_size) as total_size,
                       AVG(access_frequency) as avg_access
                FROM enhanced_script_tracking
                """
            )
            metrics = cursor.fetchone()

        results.update(self.apply_intelligent_optimizations(metrics))
        return results

    def apply_intelligent_optimizations(self, metrics: Tuple[Any, Any, Any]) -> Dict[str, Any]:
        total_files = metrics[0] or 0
        total_size = (metrics[1] or 0) / (1024 * 1024)
        avg_access = metrics[2] or 0
        return {
            "files_organized": total_files,
            "storage_optimized": f"{total_size:.2f} MB",
            "performance_improved": f"{min(avg_access * 10, 100):.0f}%",
            "enterprise_compliance": "ENFORCED",
        }
