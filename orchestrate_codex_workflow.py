#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Orchestrate Codex workflow phases with safety checks."""

import argparse
import json
import re
import subprocess
import time
from pathlib import Path
from typing import Dict, List, Tuple

REPO = Path(__file__).resolve().parent
ARTIFACTS = REPO / "artifacts"
ARTIFACTS.mkdir(exist_ok=True)
CHANGE_LOG = REPO / "change_log.md"
RESEARCH_Q = REPO / "research_questions.md"
STATUS_IDX = REPO / "docs" / "status_index.json"

SCAN_DIRS = [
    "scripts",
    "archive",
    "dashboard",
    "enterprise_modules",
    "quantum",
    "web_gui",
    "docs",
    "tests",
]

FOCUSED_TESTS = [
    "tests/documentation/test_documentation_manager_templates.py",
    "tests/test_archive_scripts.py",
    "tests/test_autonomous_setup_and_audit.py",
]

SAFETY_IGNORE = [
    ".github/workflows",
]

DANGLING_README_PATTERNS = [
    r"\[(?P<txt>[^\]]+)\]\((?P<url>[^)]+)\)",
    r"<a\s+href=\"[^\"]+\"[^>]*>(.*?)</a>",
]


def _safe_rel(path: Path) -> str:
    try:
        return str(path.relative_to(REPO))
    except Exception:
        return str(path)


def log_change(entry: str) -> None:
    CHANGE_LOG.parent.mkdir(exist_ok=True)
    with CHANGE_LOG.open("a", encoding="utf-8") as f:
        f.write(f"{time.strftime('%Y-%m-%d %H:%M:%S')} â€” {entry}\n")


def add_research_question(step: str, desc: str, error: str, ctx: str) -> None:
    RESEARCH_Q.parent.mkdir(exist_ok=True)
    with RESEARCH_Q.open("a", encoding="utf-8") as f:
        f.write(
            "Question for ChatGPT-5:\n"
            f"While performing [{step}:{desc}], encountered the following error:\n"
            f"{error}\n"
            f"Context: {ctx}\n"
            "What are the possible causes, and how can this be resolved while preserving intended functionality?\n\n"
        )


def run_cmd(cmd: List[str], step_tag: str = "", allow_fail: bool = True) -> Tuple[int, str, str]:
    try:
        proc = subprocess.run(
            cmd,
            cwd=str(REPO),
            capture_output=True,
            text=True,
            check=False,
        )
        rc, out, err = proc.returncode, proc.stdout, proc.stderr
        if rc != 0 and not allow_fail:
            raise subprocess.CalledProcessError(rc, cmd, out, err)
        return rc, out, err
    except Exception as exc:
        add_research_question(step_tag, "run_cmd", str(exc), " ".join(cmd))
        return 1, "", str(exc)


def is_safe_path(path: Path) -> bool:
    rel = _safe_rel(path)
    return not any(rel.startswith(p) for p in SAFETY_IGNORE)


def parse_and_clean_readmes() -> Dict[str, Dict[str, int]]:
    stats: Dict[str, Dict[str, int]] = {}
    for readme in list(REPO.glob("README*")) + list((REPO / "docs").glob("**/README*")):
        if not readme.is_file():
            continue
        text = readme.read_text(encoding="utf-8", errors="ignore")
        orig = text
        replaced_links = 0
        for pat in DANGLING_README_PATTERNS:
            text, n = re.subn(pat, r"\g<txt>", text)
            replaced_links += n
        if text != orig:
            readme.write_text(text, encoding="utf-8")
            stats[_safe_rel(readme)] = {"links_stripped": replaced_links}
            log_change(f"README cleaned: {_safe_rel(readme)} (links stripped: {replaced_links})")
    return stats


def discover_placeholders() -> List[Tuple[str, str, int]]:
    findings = []
    for d in SCAN_DIRS:
        root = REPO / d
        if not root.exists():
            continue
        for path in root.rglob("*.py"):
            if not is_safe_path(path):
                continue
            text = path.read_text(encoding="utf-8", errors="ignore")
            for pat in [r"\bTODO\b", r"\bpass\b", r"NotImplementedError"]:
                for m in re.finditer(pat, text):
                    findings.append((_safe_rel(path), pat, m.start()))
    return findings


def adapt_stub(path: Path) -> bool:
    try:
        text = path.read_text(encoding="utf-8", errors="ignore")
        new_text, n = re.subn(r"(?m)^\s*pass\s*$", "raise NotImplementedError('Auto-stub; needs implementation')", text)
        if n:
            path.write_text(new_text, encoding="utf-8")
            log_change(f"Stub adapted in {_safe_rel(path)} (count={n})")
            return True
        return False
    except Exception as exc:
        add_research_question("3", "adapt_stub", str(exc), _safe_rel(path))
        return False


def run_pytest(targets: List[str]) -> Dict:
    rc, out, err = run_cmd(["pytest", "-q", *targets], step_tag="pytest")
    failures = [line.strip() for line in (out + "\n" + err).splitlines() if line.strip().startswith("FAILED ")]
    return {"returncode": rc, "stdout": out, "stderr": err, "failures": failures}


def run_ruff() -> Dict:
    rc, out, err = run_cmd(["ruff", "check", "orchestrate_codex_workflow.py"], step_tag="ruff")
    count = sum(1 for line in (out + "\n" + err).splitlines() if line.strip())
    return {"returncode": rc, "count": count, "stdout": out, "stderr": err}


def run_pyright() -> Dict:
    rc, out, err = run_cmd(["pyright", "orchestrate_codex_workflow.py"], step_tag="pyright")
    match = re.search(r"Found\s+(\d+)\s+error", out + "\n" + err, re.I)
    count = int(match.group(1)) if match else (1 if rc != 0 else 0)
    return {"returncode": rc, "count": count, "stdout": out, "stderr": err}


def update_status_json(updates: Dict[str, str]) -> None:
    STATUS_IDX.parent.mkdir(parents=True, exist_ok=True)
    data = {}
    if STATUS_IDX.exists():
        try:
            data = json.loads(STATUS_IDX.read_text(encoding="utf-8"))
        except Exception:
            data = {}
    data.update(updates)
    STATUS_IDX.write_text(json.dumps(data, indent=2), encoding="utf-8")
    log_change(f"docs/status_index.json updated: {updates}")


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--fast", action="store_true")
    args = parser.parse_args()

    readme_stats = parse_and_clean_readmes()

    baseline = {}
    tests = FOCUSED_TESTS if args.fast else ["tests"]
    baseline["pytest"] = run_pytest(tests)
    baseline["ruff"] = run_ruff()
    baseline["pyright"] = run_pyright()
    (ARTIFACTS / "baseline.json").write_text(json.dumps(baseline, indent=2), encoding="utf-8")

    findings = discover_placeholders()
    (ARTIFACTS / "placeholders.json").write_text(json.dumps(findings, indent=2), encoding="utf-8")
    log_change(f"Discovered {len(findings)} placeholder markers")

    adapted = 0
    for rel, _, _ in findings:
        path = REPO / rel
        if path.suffix == ".py" and is_safe_path(path):
            if adapt_stub(path):
                adapted += 1

    post = {}
    post["pytest"] = run_pytest(tests)
    post["ruff"] = run_ruff()
    post["pyright"] = run_pyright()
    (ARTIFACTS / "post_best_effort.json").write_text(json.dumps(post, indent=2), encoding="utf-8")

    pruned = []
    if post["pytest"]["returncode"] != 0:
        for fail in post["pytest"]["failures"]:
            pruned.append({"item": fail, "rationale": "Deferred: missing specification"})
            log_change(f"PRUNED: {fail}")
    (ARTIFACTS / "pruned.json").write_text(json.dumps(pruned, indent=2), encoding="utf-8")

    if post["pytest"]["returncode"] != 0:
        add_research_question("3.1", "Run pytest", f"Failures: {len(post['pytest']['failures'])}", "pytest")
    if post["ruff"]["count"] > 0:
        add_research_question("3.2", "Run ruff", f"Issues: {post['ruff']['count']}", "ruff")
    if post["pyright"]["count"] > 0:
        add_research_question("3.2", "Run pyright", f"Errors: {post['pyright']['count']}", "pyright")

    updates = {}
    if post["pytest"]["returncode"] == 0:
        updates["flask-dashboard"] = "finished"
        updates["database-synchronization-engine"] = "finished"
    if updates:
        update_status_json(updates)

    final_report = {
        "readme_stats": readme_stats,
        "placeholders_found": len(findings),
        "stubs_adapted": adapted,
        "baseline": baseline,
        "post_best_effort": post,
        "pruned": pruned,
    }
    (ARTIFACTS / "final_report.json").write_text(json.dumps(final_report, indent=2), encoding="utf-8")

    print(json.dumps({
        "summary": {
            "pytest_pass": post["pytest"]["returncode"] == 0,
            "ruff_remaining": post["ruff"]["count"],
            "pyright_remaining": post["pyright"]["count"],
            "stubs_adapted": adapted,
        },
        "artifacts": [str(p.relative_to(REPO)) for p in ARTIFACTS.glob("*")],
        "change_log": _safe_rel(CHANGE_LOG),
        "research_questions": _safe_rel(RESEARCH_Q),
        "status_index": _safe_rel(STATUS_IDX),
    }, indent=2))

if __name__ == "__main__":
    main()
